{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import torch\n",
    "import tqdm\n",
    "from scipy.spatial.distance import cosine\n",
    "import transformers as tfm\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['bert','bertLarge','gpt2', 'roberta', 'mpnet']\n",
    "models_output_size = {'bert':768,'bertLarge':1024,'gpt2':768,'roberta':768,'mpnet':768}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers_func = [tfm.BertTokenizer,tfm.BertTokenizer,tfm.GPT2Tokenizer,tfm.RobertaTokenizer,tfm.MPNetTokenizer]\n",
    "models_func = [tfm.BertModel,tfm.BertModel,tfm.GPT2Model,tfm.RobertaModel,tfm.MPNetModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/bastien/Downloads/LanguageModels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/bastien/Downloads/LanguageModels/bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/bastien/Downloads/LanguageModels/bertLarge were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/bastien/Downloads/LanguageModels/roberta were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /home/bastien/Downloads/LanguageModels/mpnet were not used when initializing MPNetModel: ['lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MPNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at /home/bastien/Downloads/LanguageModels/mpnet and are newly initialized: ['mpnet.pooler.dense.bias', 'mpnet.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizers = {models_list[i] : tokenizers_func[i].from_pretrained(path+models_list[i]) for i in range(len(models_list))}\n",
    "models = {models_list[i] : models_func[i].from_pretrained(path+models_list[i]) for i in range(len(models_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = ['I come from', 'He lives in', 'She moved to']\n",
    "short_ctxts = ['come','lives','moved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('./csv/worldcitiespop.csv',header=0,dtype={'AccentCity':'str', 'Region':'object'}).dropna().drop('Region',axis=1)\n",
    "cities = cities[cities.Population>100000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>AccentCity</th>\n",
       "      <th>Population</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ae</td>\n",
       "      <td>abu dhabi</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>603687.0</td>\n",
       "      <td>24.466667</td>\n",
       "      <td>54.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae</td>\n",
       "      <td>dubai</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>1137376.0</td>\n",
       "      <td>25.258172</td>\n",
       "      <td>55.304717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae</td>\n",
       "      <td>sharjah</td>\n",
       "      <td>Sharjah</td>\n",
       "      <td>543942.0</td>\n",
       "      <td>25.357310</td>\n",
       "      <td>55.403304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af</td>\n",
       "      <td>baglan</td>\n",
       "      <td>Baglan</td>\n",
       "      <td>108481.0</td>\n",
       "      <td>36.130684</td>\n",
       "      <td>68.708286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af</td>\n",
       "      <td>gardez</td>\n",
       "      <td>Gardez</td>\n",
       "      <td>103732.0</td>\n",
       "      <td>33.597439</td>\n",
       "      <td>69.225922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>zw</td>\n",
       "      <td>gweru</td>\n",
       "      <td>Gweru</td>\n",
       "      <td>201879.0</td>\n",
       "      <td>-19.450000</td>\n",
       "      <td>29.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>zw</td>\n",
       "      <td>harare</td>\n",
       "      <td>Harare</td>\n",
       "      <td>2213701.0</td>\n",
       "      <td>-17.817778</td>\n",
       "      <td>31.044722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>zw</td>\n",
       "      <td>kadoma</td>\n",
       "      <td>Kadoma</td>\n",
       "      <td>100276.0</td>\n",
       "      <td>-18.350000</td>\n",
       "      <td>29.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>zw</td>\n",
       "      <td>kwekwe</td>\n",
       "      <td>Kwekwe</td>\n",
       "      <td>116332.0</td>\n",
       "      <td>-18.916667</td>\n",
       "      <td>29.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>zw</td>\n",
       "      <td>mutare</td>\n",
       "      <td>Mutare</td>\n",
       "      <td>253449.0</td>\n",
       "      <td>-18.966667</td>\n",
       "      <td>32.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3527 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country       City AccentCity  Population   Latitude  Longitude\n",
       "0         ae  abu dhabi  Abu Dhabi    603687.0  24.466667  54.366667\n",
       "1         ae      dubai      Dubai   1137376.0  25.258172  55.304717\n",
       "2         ae    sharjah    Sharjah    543942.0  25.357310  55.403304\n",
       "3         af     baglan     Baglan    108481.0  36.130684  68.708286\n",
       "4         af     gardez     Gardez    103732.0  33.597439  69.225922\n",
       "...      ...        ...        ...         ...        ...        ...\n",
       "3522      zw      gweru      Gweru    201879.0 -19.450000  29.816667\n",
       "3523      zw     harare     Harare   2213701.0 -17.817778  31.044722\n",
       "3524      zw     kadoma     Kadoma    100276.0 -18.350000  29.916667\n",
       "3525      zw     kwekwe     Kwekwe    116332.0 -18.916667  29.816667\n",
       "3526      zw     mutare     Mutare    253449.0 -18.966667  32.666667\n",
       "\n",
       "[3527 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CapitalName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Somaliland</td>\n",
       "      <td>Hargeisa</td>\n",
       "      <td>9.550000</td>\n",
       "      <td>44.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Georgia and South Sandwich Islands</td>\n",
       "      <td>King Edward Point</td>\n",
       "      <td>-54.283333</td>\n",
       "      <td>-36.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French Southern and Antarctic Lands</td>\n",
       "      <td>Port-aux-Français</td>\n",
       "      <td>-49.350000</td>\n",
       "      <td>70.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Palestine</td>\n",
       "      <td>Jerusalem</td>\n",
       "      <td>31.766667</td>\n",
       "      <td>35.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aland Islands</td>\n",
       "      <td>Mariehamn</td>\n",
       "      <td>60.116667</td>\n",
       "      <td>19.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Harare</td>\n",
       "      <td>-17.816667</td>\n",
       "      <td>31.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Northern Cyprus</td>\n",
       "      <td>North Nicosia</td>\n",
       "      <td>35.183333</td>\n",
       "      <td>33.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>22.302711</td>\n",
       "      <td>114.177216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>British Indian Ocean Territory</td>\n",
       "      <td>Diego Garcia</td>\n",
       "      <td>-7.300000</td>\n",
       "      <td>72.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Macau</td>\n",
       "      <td>Macau</td>\n",
       "      <td>22.210928</td>\n",
       "      <td>113.552971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  CountryName        CapitalName   Latitude  \\\n",
       "0                                  Somaliland           Hargeisa   9.550000   \n",
       "1    South Georgia and South Sandwich Islands  King Edward Point -54.283333   \n",
       "2         French Southern and Antarctic Lands  Port-aux-Français -49.350000   \n",
       "3                                   Palestine          Jerusalem  31.766667   \n",
       "4                               Aland Islands          Mariehamn  60.116667   \n",
       "..                                        ...                ...        ...   \n",
       "237                                  Zimbabwe             Harare -17.816667   \n",
       "238                           Northern Cyprus      North Nicosia  35.183333   \n",
       "239                                 Hong Kong          Hong Kong  22.302711   \n",
       "240            British Indian Ocean Territory       Diego Garcia  -7.300000   \n",
       "241                                     Macau              Macau  22.210928   \n",
       "\n",
       "      Longitude  \n",
       "0     44.050000  \n",
       "1    -36.500000  \n",
       "2     70.216667  \n",
       "3     35.233333  \n",
       "4     19.900000  \n",
       "..          ...  \n",
       "237   31.033333  \n",
       "238   33.366667  \n",
       "239  114.177216  \n",
       "240   72.400000  \n",
       "241  113.552971  \n",
       "\n",
       "[242 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitals = pd.read_csv('./csv/country-capitals.csv').drop(['ContinentName','CountryCode'], axis=1)\n",
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>AX</td>\n",
       "      <td>60.1500</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>-14.3333</td>\n",
       "      <td>-170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>WF</td>\n",
       "      <td>-13.3000</td>\n",
       "      <td>-176.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>EH</td>\n",
       "      <td>24.5000</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>YE</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZM</td>\n",
       "      <td>-15.0000</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>-20.0000</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Code  Latitude  Longitude\n",
       "0          Afghanistan   AF   33.0000       65.0\n",
       "1        Åland Islands   AX   60.1500       20.0\n",
       "2              Albania   AL   41.0000       20.0\n",
       "3              Algeria   DZ   28.0000        3.0\n",
       "4       American Samoa   AS  -14.3333     -170.0\n",
       "..                 ...  ...       ...        ...\n",
       "244  Wallis and Futuna   WF  -13.3000     -176.2\n",
       "245     Western Sahara   EH   24.5000      -13.0\n",
       "246              Yemen   YE   15.0000       48.0\n",
       "247             Zambia   ZM  -15.0000       30.0\n",
       "248           Zimbabwe   ZW  -20.0000       30.0\n",
       "\n",
       "[249 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = pd.read_csv('./csv/countries.csv')\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inner:   0%|          | 0.00/3.00 [00:00<?, ?it/s]fav\n",
      "inner:  33%|███▎      | 1.00/3.00 [00:00<00:00, 9.96it/s]lives\n",
      "inner:  67%|██████▋   | 2.00/3.00 [00:00<00:00, 9.90it/s]moved\n",
      "inner: 100%|██████████| 3.00/3.00 [00:00<00:00, 9.84it/s]\n",
      "\n",
      "inner:   0%|          | 0.00/3.00 [00:00<?, ?it/s]fav\n",
      "inner:  33%|███▎      | 1.00/3.00 [00:00<00:00, 9.97it/s]lives\n",
      "inner:  67%|██████▋   | 2.00/3.00 [00:00<00:00, 9.86it/s]moved\n",
      "inner: 100%|██████████| 3.00/3.00 [00:00<00:00, 9.84it/s]\n",
      "\n",
      "inner:   0%|          | 0.00/3.00 [00:00<?, ?it/s]fav\n",
      "inner:  33%|███▎      | 1.00/3.00 [00:00<00:00, 9.97it/s]lives\n",
      "inner:  67%|██████▋   | 2.00/3.00 [00:00<00:00, 9.89it/s]moved\n",
      "inner: 100%|██████████| 3.00/3.00 [00:00<00:00, 9.84it/s]\n",
      "\n",
      "inner:   0%|          | 0.00/3.00 [00:00<?, ?it/s]fav\n",
      "inner:  33%|███▎      | 1.00/3.00 [00:00<00:00, 9.96it/s]lives\n",
      "inner:  67%|██████▋   | 2.00/3.00 [00:00<00:00, 9.89it/s]moved\n",
      "inner: 100%|██████████| 3.00/3.00 [00:00<00:00, 9.84it/s]\n",
      "\n",
      "inner:   0%|          | 0.00/3.00 [00:00<?, ?it/s]fav\n",
      "inner:  33%|███▎      | 1.00/3.00 [00:00<00:00, 9.97it/s]lives\n",
      "inner:  67%|██████▋   | 2.00/3.00 [00:00<00:00, 9.90it/s]moved\n",
      "inner: 100%|██████████| 3.00/3.00 [00:00<00:00, 9.84it/s]\n",
      "\n",
      "slt: 5it [00:01,  3.23it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i,c in tqdm.tqdm(enumerate(models_list),desc='slt',file=sys.stdout,position=1):\n",
    "    #print(i,c)\n",
    "    for j in tqdm.tqdm(short_ctxts,desc='inner',unit_scale=True,file=sys.stdout,position=0):\n",
    "        time.sleep(0.1)\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010970830917358398"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "\n",
    "token = tokenizers[model_name]\n",
    "model = models[model_name]\n",
    "\n",
    "inputs = token(\"Hello my dog is cute\", return_tensors=\"pt\")\n",
    "outputs1 = model(**inputs)\n",
    "\n",
    "\n",
    "inputs = token(\"Hello my cat is cute\".split(), return_tensors=\"pt\",is_split_into_words=True)\n",
    "outputs2 = model(**inputs)\n",
    "\n",
    "ind_compar = 2\n",
    "cosine(outputs1.last_hidden_state[0][ind_compar].detach().numpy(), outputs2.last_hidden_state[0][ind_compar].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "ind = 100\n",
    "ctx=contexts[i]\n",
    "\n",
    "for entry in cities.AccentCity :\n",
    "    inputs = token(ctx+\" \"+entry,return_tensors=\"pt\")\n",
    "    \n",
    "    #If the entry is split in multiple tokens, we need to aggregate the tensors\n",
    "    entry_tokens = token([entry],is_split_into_words=True,add_special_tokens=False)['input_ids']\n",
    "\n",
    "    expected_length = len(token([entry],is_split_into_words=True,add_special_tokens=False)['input_ids']) #number of tokens for the entry\n",
    "    last_ctx_token = token(ctx,add_special_tokens=False)['input_ids'][-1] #last token of the context string\n",
    "    start_index = inputs['input_ids'][0].tolist().index(last_ctx_token)+1 #first index of the entry's tensors\n",
    "    if inputs['input_ids'][0][start_index:start_index+expected_length].tolist()!= entry_tokens:\n",
    "        print(entry_tokens)\n",
    "        print(inputs['input_ids'][0][start_index:start_index+expected_length])\n",
    "        raise ValueError()\n",
    "\n",
    "\n",
    "#entry_embedding = outputs.last_hidden_state[0][start_index:start_index+expected_length].mean(axis=0)\n",
    "\n",
    "#entry_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class tqdm in module tqdm.std:\n",
      "\n",
      "class tqdm(tqdm.utils.Comparable)\n",
      " |  tqdm(*_, **__)\n",
      " |  \n",
      " |  Decorate an iterable object, returning an iterator which acts exactly\n",
      " |  like the original iterable, but prints a dynamically updating\n",
      " |  progressbar every time a value is requested.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      tqdm\n",
      " |      tqdm.utils.Comparable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, iterable=None, desc=None, total=None, leave=True, file=None, ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None, ascii=None, disable=False, unit='it', unit_scale=False, dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0, position=None, postfix=None, unit_divisor=1000, write_bytes=None, lock_args=None, nrows=None, colour=None, delay=0, gui=False, **kwargs)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      iterable  : iterable, optional\n",
      " |          Iterable to decorate with a progressbar.\n",
      " |          Leave blank to manually manage the updates.\n",
      " |      desc  : str, optional\n",
      " |          Prefix for the progressbar.\n",
      " |      total  : int or float, optional\n",
      " |          The number of expected iterations. If unspecified,\n",
      " |          len(iterable) is used if possible. If float(\"inf\") or as a last\n",
      " |          resort, only basic progress statistics are displayed\n",
      " |          (no ETA, no progressbar).\n",
      " |          If `gui` is True and this parameter needs subsequent updating,\n",
      " |          specify an initial arbitrary large positive number,\n",
      " |          e.g. 9e9.\n",
      " |      leave  : bool, optional\n",
      " |          If [default: True], keeps all traces of the progressbar\n",
      " |          upon termination of iteration.\n",
      " |          If `None`, will leave only if `position` is `0`.\n",
      " |      file  : `io.TextIOWrapper` or `io.StringIO`, optional\n",
      " |          Specifies where to output the progress messages\n",
      " |          (default: sys.stderr). Uses `file.write(str)` and `file.flush()`\n",
      " |          methods.  For encoding, see `write_bytes`.\n",
      " |      ncols  : int, optional\n",
      " |          The width of the entire output message. If specified,\n",
      " |          dynamically resizes the progressbar to stay within this bound.\n",
      " |          If unspecified, attempts to use environment width. The\n",
      " |          fallback is a meter width of 10 and no limit for the counter and\n",
      " |          statistics. If 0, will not print any meter (only stats).\n",
      " |      mininterval  : float, optional\n",
      " |          Minimum progress display update interval [default: 0.1] seconds.\n",
      " |      maxinterval  : float, optional\n",
      " |          Maximum progress display update interval [default: 10] seconds.\n",
      " |          Automatically adjusts `miniters` to correspond to `mininterval`\n",
      " |          after long display update lag. Only works if `dynamic_miniters`\n",
      " |          or monitor thread is enabled.\n",
      " |      miniters  : int or float, optional\n",
      " |          Minimum progress display update interval, in iterations.\n",
      " |          If 0 and `dynamic_miniters`, will automatically adjust to equal\n",
      " |          `mininterval` (more CPU efficient, good for tight loops).\n",
      " |          If > 0, will skip display of specified number of iterations.\n",
      " |          Tweak this and `mininterval` to get very efficient loops.\n",
      " |          If your progress is erratic with both fast and slow iterations\n",
      " |          (network, skipping items, etc) you should set miniters=1.\n",
      " |      ascii  : bool or str, optional\n",
      " |          If unspecified or False, use unicode (smooth blocks) to fill\n",
      " |          the meter. The fallback is to use ASCII characters \" 123456789#\".\n",
      " |      disable  : bool, optional\n",
      " |          Whether to disable the entire progressbar wrapper\n",
      " |          [default: False]. If set to None, disable on non-TTY.\n",
      " |      unit  : str, optional\n",
      " |          String that will be used to define the unit of each iteration\n",
      " |          [default: it].\n",
      " |      unit_scale  : bool or int or float, optional\n",
      " |          If 1 or True, the number of iterations will be reduced/scaled\n",
      " |          automatically and a metric prefix following the\n",
      " |          International System of Units standard will be added\n",
      " |          (kilo, mega, etc.) [default: False]. If any other non-zero\n",
      " |          number, will scale `total` and `n`.\n",
      " |      dynamic_ncols  : bool, optional\n",
      " |          If set, constantly alters `ncols` and `nrows` to the\n",
      " |          environment (allowing for window resizes) [default: False].\n",
      " |      smoothing  : float, optional\n",
      " |          Exponential moving average smoothing factor for speed estimates\n",
      " |          (ignored in GUI mode). Ranges from 0 (average speed) to 1\n",
      " |          (current/instantaneous speed) [default: 0.3].\n",
      " |      bar_format  : str, optional\n",
      " |          Specify a custom bar string formatting. May impact performance.\n",
      " |          [default: '{l_bar}{bar}{r_bar}'], where\n",
      " |          l_bar='{desc}: {percentage:3.0f}%|' and\n",
      " |          r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n",
      " |            '{rate_fmt}{postfix}]'\n",
      " |          Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n",
      " |            percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n",
      " |            rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n",
      " |            rate_inv, rate_inv_fmt, postfix, unit_divisor,\n",
      " |            remaining, remaining_s, eta.\n",
      " |          Note that a trailing \": \" is automatically removed after {desc}\n",
      " |          if the latter is empty.\n",
      " |      initial  : int or float, optional\n",
      " |          The initial counter value. Useful when restarting a progress\n",
      " |          bar [default: 0]. If using float, consider specifying `{n:.3f}`\n",
      " |          or similar in `bar_format`, or specifying `unit_scale`.\n",
      " |      position  : int, optional\n",
      " |          Specify the line offset to print this bar (starting from 0)\n",
      " |          Automatic if unspecified.\n",
      " |          Useful to manage multiple bars at once (eg, from threads).\n",
      " |      postfix  : dict or *, optional\n",
      " |          Specify additional stats to display at the end of the bar.\n",
      " |          Calls `set_postfix(**postfix)` if possible (dict).\n",
      " |      unit_divisor  : float, optional\n",
      " |          [default: 1000], ignored unless `unit_scale` is True.\n",
      " |      write_bytes  : bool, optional\n",
      " |          If (default: None) and `file` is unspecified,\n",
      " |          bytes will be written in Python 2. If `True` will also write\n",
      " |          bytes. In all other cases will default to unicode.\n",
      " |      lock_args  : tuple, optional\n",
      " |          Passed to `refresh` for intermediate output\n",
      " |          (initialisation, iterating, and updating).\n",
      " |      nrows  : int, optional\n",
      " |          The screen height. If specified, hides nested bars outside this\n",
      " |          bound. If unspecified, attempts to use environment height.\n",
      " |          The fallback is 20.\n",
      " |      colour  : str, optional\n",
      " |          Bar colour (e.g. 'green', '#00ff00').\n",
      " |      delay  : float, optional\n",
      " |          Don't display until [default: 0] seconds have elapsed.\n",
      " |      gui  : bool, optional\n",
      " |          WARNING: internal parameter - do not use.\n",
      " |          Use tqdm.gui.tqdm(...) instead. If set, will attempt to use\n",
      " |          matplotlib animations for a graphical output [default: False].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : decorated iterator.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Backward-compatibility to use: for x in tqdm(iterable)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  clear(self, nolock=False)\n",
      " |      Clear current bar display.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Cleanup and (if leave=False) close the progressbar.\n",
      " |  \n",
      " |  display(self, msg=None, pos=None)\n",
      " |      Use `self.sp` to display `msg` in the specified `pos`.\n",
      " |      \n",
      " |      Consider overloading this function when inheriting to use e.g.:\n",
      " |      `self.some_frontend(**self.format_dict)` instead of `self.sp`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      msg  : str, optional. What to display (default: `repr(self)`).\n",
      " |      pos  : int, optional. Position to `moveto`\n",
      " |        (default: `abs(self.pos)`).\n",
      " |  \n",
      " |  moveto(self, n)\n",
      " |  \n",
      " |  refresh(self, nolock=False, lock_args=None)\n",
      " |      Force refresh the display of this bar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nolock  : bool, optional\n",
      " |          If `True`, does not lock.\n",
      " |          If [default: `False`]: calls `acquire()` on internal lock.\n",
      " |      lock_args  : tuple, optional\n",
      " |          Passed to internal lock's `acquire()`.\n",
      " |          If specified, will only `display()` if `acquire()` returns `True`.\n",
      " |  \n",
      " |  reset(self, total=None)\n",
      " |      Resets to 0 iterations for repeated use.\n",
      " |      \n",
      " |      Consider combining with `leave=True`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      total  : int or float, optional. Total to use for the new bar.\n",
      " |  \n",
      " |  set_description(self, desc=None, refresh=True)\n",
      " |      Set/modify description of the progress bar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      desc  : str, optional\n",
      " |      refresh  : bool, optional\n",
      " |          Forces refresh [default: True].\n",
      " |  \n",
      " |  set_description_str(self, desc=None, refresh=True)\n",
      " |      Set/modify description without ': ' appended.\n",
      " |  \n",
      " |  set_postfix(self, ordered_dict=None, refresh=True, **kwargs)\n",
      " |      Set/modify postfix (additional stats)\n",
      " |      with automatic formatting based on datatype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ordered_dict  : dict or OrderedDict, optional\n",
      " |      refresh  : bool, optional\n",
      " |          Forces refresh [default: True].\n",
      " |      kwargs  : dict, optional\n",
      " |  \n",
      " |  set_postfix_str(self, s='', refresh=True)\n",
      " |      Postfix without dictionary expansion, similar to prefix handling.\n",
      " |  \n",
      " |  unpause(self)\n",
      " |      Restart tqdm timer from last print time.\n",
      " |  \n",
      " |  update(self, n=1)\n",
      " |      Manually update the progress bar, useful for streams\n",
      " |      such as reading files.\n",
      " |      E.g.:\n",
      " |      >>> t = tqdm(total=filesize) # Initialise\n",
      " |      >>> for current_buffer in stream:\n",
      " |      ...    ...\n",
      " |      ...    t.update(len(current_buffer))\n",
      " |      >>> t.close()\n",
      " |      The last line is highly recommended, but possibly not necessary if\n",
      " |      `t.update()` will be called in such a way that `filesize` will be\n",
      " |      exactly reached and printed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int or float, optional\n",
      " |          Increment to add to the internal counter of iterations\n",
      " |          [default: 1]. If using float, consider specifying `{n:.3f}`\n",
      " |          or similar in `bar_format`, or specifying `unit_scale`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : bool or None\n",
      " |          True if a `display()` was triggered.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  external_write_mode(file=None, nolock=False) from builtins.type\n",
      " |      Disable tqdm within context and refresh tqdm when exits.\n",
      " |      Useful when writing to standard output stream\n",
      " |  \n",
      " |  get_lock() from builtins.type\n",
      " |      Get the global lock. Construct it if it does not exist.\n",
      " |  \n",
      " |  pandas(**tqdm_kwargs) from builtins.type\n",
      " |      Registers the current `tqdm` class with\n",
      " |          pandas.core.\n",
      " |          ( frame.DataFrame\n",
      " |          | series.Series\n",
      " |          | groupby.(generic.)DataFrameGroupBy\n",
      " |          | groupby.(generic.)SeriesGroupBy\n",
      " |          ).progress_apply\n",
      " |      \n",
      " |      A new instance will be create every time `progress_apply` is called,\n",
      " |      and each instance will automatically `close()` upon completion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tqdm_kwargs  : arguments for the tqdm instance\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> import numpy as np\n",
      " |      >>> from tqdm import tqdm\n",
      " |      >>> from tqdm.gui import tqdm as tqdm_gui\n",
      " |      >>>\n",
      " |      >>> df = pd.DataFrame(np.random.randint(0, 100, (100000, 6)))\n",
      " |      >>> tqdm.pandas(ncols=50)  # can use tqdm_gui, optional kwargs, etc\n",
      " |      >>> # Now you can use `progress_apply` instead of `apply`\n",
      " |      >>> df.groupby(0).progress_apply(lambda x: x**2)\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      <https://stackoverflow.com/questions/18603270/        progress-indicator-during-pandas-operations-python>\n",
      " |  \n",
      " |  set_lock(lock) from builtins.type\n",
      " |      Set the global lock.\n",
      " |  \n",
      " |  wrapattr(stream, method, total=None, bytes=True, **tqdm_kwargs) from builtins.type\n",
      " |      stream  : file-like object.\n",
      " |      method  : str, \"read\" or \"write\". The result of `read()` and\n",
      " |          the first argument of `write()` should have a `len()`.\n",
      " |      \n",
      " |      >>> with tqdm.wrapattr(file_obj, \"read\", total=file_obj.size) as fobj:\n",
      " |      ...     while True:\n",
      " |      ...         chunk = fobj.read(chunk_size)\n",
      " |      ...         if not chunk:\n",
      " |      ...             break\n",
      " |  \n",
      " |  write(s, file=None, end='\\n', nolock=False) from builtins.type\n",
      " |      Print a message via tqdm (without overlap with bars).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(cls, *_, **__)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  format_interval(t)\n",
      " |      Formats a number of seconds as a clock time, [H:]MM:SS\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      t  : int\n",
      " |          Number of seconds.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          [H:]MM:SS\n",
      " |  \n",
      " |  format_meter(n, total, elapsed, ncols=None, prefix='', ascii=False, unit='it', unit_scale=False, rate=None, bar_format=None, postfix=None, unit_divisor=1000, initial=0, colour=None, **extra_kwargs)\n",
      " |      Return a string-based progress bar given some parameters\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int or float\n",
      " |          Number of finished iterations.\n",
      " |      total  : int or float\n",
      " |          The expected total number of iterations. If meaningless (None),\n",
      " |          only basic progress statistics are displayed (no ETA).\n",
      " |      elapsed  : float\n",
      " |          Number of seconds passed since start.\n",
      " |      ncols  : int, optional\n",
      " |          The width of the entire output message. If specified,\n",
      " |          dynamically resizes `{bar}` to stay within this bound\n",
      " |          [default: None]. If `0`, will not print any bar (only stats).\n",
      " |          The fallback is `{bar:10}`.\n",
      " |      prefix  : str, optional\n",
      " |          Prefix message (included in total width) [default: ''].\n",
      " |          Use as {desc} in bar_format string.\n",
      " |      ascii  : bool, optional or str, optional\n",
      " |          If not set, use unicode (smooth blocks) to fill the meter\n",
      " |          [default: False]. The fallback is to use ASCII characters\n",
      " |          \" 123456789#\".\n",
      " |      unit  : str, optional\n",
      " |          The iteration unit [default: 'it'].\n",
      " |      unit_scale  : bool or int or float, optional\n",
      " |          If 1 or True, the number of iterations will be printed with an\n",
      " |          appropriate SI metric prefix (k = 10^3, M = 10^6, etc.)\n",
      " |          [default: False]. If any other non-zero number, will scale\n",
      " |          `total` and `n`.\n",
      " |      rate  : float, optional\n",
      " |          Manual override for iteration rate.\n",
      " |          If [default: None], uses n/elapsed.\n",
      " |      bar_format  : str, optional\n",
      " |          Specify a custom bar string formatting. May impact performance.\n",
      " |          [default: '{l_bar}{bar}{r_bar}'], where\n",
      " |          l_bar='{desc}: {percentage:3.0f}%|' and\n",
      " |          r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n",
      " |            '{rate_fmt}{postfix}]'\n",
      " |          Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n",
      " |            percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n",
      " |            rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n",
      " |            rate_inv, rate_inv_fmt, postfix, unit_divisor,\n",
      " |            remaining, remaining_s, eta.\n",
      " |          Note that a trailing \": \" is automatically removed after {desc}\n",
      " |          if the latter is empty.\n",
      " |      postfix  : *, optional\n",
      " |          Similar to `prefix`, but placed at the end\n",
      " |          (e.g. for additional stats).\n",
      " |          Note: postfix is usually a string (not a dict) for this method,\n",
      " |          and will if possible be set to postfix = ', ' + postfix.\n",
      " |          However other types are supported (#382).\n",
      " |      unit_divisor  : float, optional\n",
      " |          [default: 1000], ignored unless `unit_scale` is True.\n",
      " |      initial  : int or float, optional\n",
      " |          The initial counter value [default: 0].\n",
      " |      colour  : str, optional\n",
      " |          Bar colour (e.g. 'green', '#00ff00').\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : Formatted meter and stats, ready to display.\n",
      " |  \n",
      " |  format_num(n)\n",
      " |      Intelligent scientific notation (.3g).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n  : int or float or Numeric\n",
      " |          A Number.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          Formatted number.\n",
      " |  \n",
      " |  format_sizeof(num, suffix='', divisor=1000)\n",
      " |      Formats a number (greater than unity) with SI Order of Magnitude\n",
      " |      prefixes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num  : float\n",
      " |          Number ( >= 1) to format.\n",
      " |      suffix  : str, optional\n",
      " |          Post-postfix [default: ''].\n",
      " |      divisor  : float, optional\n",
      " |          Divisor between prefixes [default: 1000].\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out  : str\n",
      " |          Number with Order of Magnitude SI unit postfix.\n",
      " |  \n",
      " |  status_printer(file)\n",
      " |      Manage the printing and in-place updating of a line of characters.\n",
      " |      Note that if the string is longer than a line, then in-place\n",
      " |      updating may not work (it will print a new line at each refresh).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  format_dict\n",
      " |      Public API for read-only member access.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  monitor = <TMonitor(Thread-4, started daemon 139938638235392)>\n",
      " |  \n",
      " |  monitor_interval = 10\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tqdm.utils.Comparable:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tqdm.utils.Comparable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tqdm.tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert : come:   4%|▍         | 147/3527 [00:15<05:45,  9.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f2ebc60b95db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccentCity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshort_ctxts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "for j, entry in tqdm.tqdm(enumerate(cities.AccentCity),desc=model_name + ' : ' + short_ctxts[0], total=len(cities)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert : come: 100%|██████████| 3.53k/3.53k [05:13<00:00, 11.2it/s]\n",
      "bert : lives: 100%|██████████| 3.53k/3.53k [04:32<00:00, 12.9it/s]\n",
      "bert : moved: 100%|██████████| 3.53k/3.53k [04:16<00:00, 13.7it/s]\n",
      "bertLarge : come: 100%|██████████| 3.53k/3.53k [13:27<00:00, 4.37it/s]  \n",
      "bertLarge : lives: 100%|██████████| 3.53k/3.53k [13:33<00:00, 4.34it/s]\n",
      "bertLarge : moved: 100%|██████████| 3.53k/3.53k [13:38<00:00, 4.31it/s]\n",
      "gpt2 : come: 100%|██████████| 3.53k/3.53k [04:28<00:00, 13.1it/s] \n",
      "gpt2 : lives: 100%|██████████| 3.53k/3.53k [04:18<00:00, 13.6it/s]\n",
      "gpt2 : moved: 100%|██████████| 3.53k/3.53k [04:04<00:00, 14.4it/s]\n",
      "roberta : come: 100%|██████████| 3.53k/3.53k [04:03<00:00, 14.5it/s] \n",
      "roberta : lives: 100%|██████████| 3.53k/3.53k [03:48<00:00, 15.4it/s]\n",
      "roberta : moved: 100%|██████████| 3.53k/3.53k [03:54<00:00, 15.0it/s]\n",
      "mpnet : come: 100%|██████████| 3.53k/3.53k [04:13<00:00, 13.9it/s]\n",
      "mpnet : lives: 100%|██████████| 3.53k/3.53k [04:06<00:00, 14.3it/s]\n",
      "mpnet : moved: 100%|██████████| 3.53k/3.53k [04:11<00:00, 14.0it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cities\n",
    "series = cities.AccentCity\n",
    "for model_name in models_list:\n",
    "    token = tokenizers[model_name]\n",
    "    model = models[model_name]\n",
    "    size = models_output_size[model_name]\n",
    "    for i, ctx in enumerate(contexts):\n",
    "        buffer_arr = np.empty((len(series),size))\n",
    "        for ind,entry in tqdm.tqdm(enumerate(series),desc=model_name + ' : ' + short_ctxts[i], unit_scale=True, total=len(series)):\n",
    "            inputs = token(ctx+\" \"+entry,return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            #If the entry is split in multiple tokens, we need to aggregate the tensors\n",
    "            expected_length = len(token([entry],is_split_into_words=True,add_special_tokens=False)['input_ids']) #number of tokens for the entry\n",
    "            last_ctx_token = token(ctx,add_special_tokens=False)['input_ids'][-1] #last token of the context string\n",
    "            start_index = inputs['input_ids'][0].tolist().index(last_ctx_token)+1 #first index of the entry's tensors\n",
    "\n",
    "            entry_embedding = outputs.last_hidden_state[0][start_index:start_index+expected_length].mean(axis=0)\n",
    "            buffer_arr[ind] = entry_embedding.detach().numpy()\n",
    "    \n",
    "        with open('embd_files/'+model_name+'_'+ short_ctxts[i] + '_cities.npy','wb') as f:\n",
    "            np.save(file=f,arr=buffer_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert : come: 100%|██████████| 242/242 [00:18<00:00, 12.9it/s] \n",
      "bert : lives: 100%|██████████| 242/242 [00:16<00:00, 14.4it/s] \n",
      "bert : moved: 100%|██████████| 242/242 [00:18<00:00, 13.1it/s] \n",
      "bertLarge : come: 100%|██████████| 242/242 [00:57<00:00, 4.23it/s] \n",
      "bertLarge : lives: 100%|██████████| 242/242 [00:55<00:00, 4.36it/s] \n",
      "bertLarge : moved: 100%|██████████| 242/242 [00:55<00:00, 4.33it/s] \n",
      "gpt2 : come: 100%|██████████| 242/242 [00:17<00:00, 13.6it/s] \n",
      "gpt2 : lives: 100%|██████████| 242/242 [00:17<00:00, 13.9it/s] \n",
      "gpt2 : moved: 100%|██████████| 242/242 [00:17<00:00, 13.9it/s] \n",
      "roberta : come: 100%|██████████| 242/242 [00:17<00:00, 14.0it/s] \n",
      "roberta : lives: 100%|██████████| 242/242 [00:20<00:00, 12.0it/s] \n",
      "roberta : moved: 100%|██████████| 242/242 [00:17<00:00, 13.6it/s] \n",
      "mpnet : come: 100%|██████████| 242/242 [00:17<00:00, 14.1it/s] \n",
      "mpnet : lives: 100%|██████████| 242/242 [00:17<00:00, 14.2it/s] \n",
      "mpnet : moved: 100%|██████████| 242/242 [00:16<00:00, 14.4it/s] \n"
     ]
    }
   ],
   "source": [
    "# Capitals\n",
    "series = capitals.CapitalName\n",
    "for model_name in models_list:\n",
    "    token = tokenizers[model_name]\n",
    "    model = models[model_name]\n",
    "    size = models_output_size[model_name]\n",
    "    for i, ctx in enumerate(contexts):\n",
    "        buffer_arr = np.empty((len(series),size))\n",
    "        for ind,entry in tqdm.tqdm(enumerate(series),desc=model_name + ' : ' + short_ctxts[i], unit_scale=True, total=len(series)):\n",
    "            inputs = token(ctx+\" \"+entry,return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            #If the entry is split in multiple tokens, we need to aggregate the tensors\n",
    "            expected_length = len(token([entry],is_split_into_words=True,add_special_tokens=False)['input_ids']) #number of tokens for the entry\n",
    "            last_ctx_token = token(ctx,add_special_tokens=False)['input_ids'][-1] #last token of the context string\n",
    "            start_index = inputs['input_ids'][0].tolist().index(last_ctx_token)+1 #first index of the entry's tensors\n",
    "\n",
    "            entry_embedding = outputs.last_hidden_state[0][start_index:start_index+expected_length].mean(axis=0)\n",
    "            buffer_arr[ind] = entry_embedding.detach().numpy()\n",
    "    \n",
    "        with open('embd_files/'+model_name+'_'+ short_ctxts[i] + '_capitals.npy','wb') as f:\n",
    "            np.save(file=f,arr=buffer_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert : come: 100%|██████████| 249/249 [00:18<00:00, 13.6it/s] \n",
      "bert : lives: 100%|██████████| 249/249 [00:18<00:00, 13.8it/s] \n",
      "bert : moved: 100%|██████████| 249/249 [00:17<00:00, 13.8it/s] \n",
      "bertLarge : come: 100%|██████████| 249/249 [00:57<00:00, 4.34it/s] \n",
      "bertLarge : lives: 100%|██████████| 249/249 [00:59<00:00, 4.18it/s] \n",
      "bertLarge : moved: 100%|██████████| 249/249 [00:56<00:00, 4.42it/s] \n",
      "gpt2 : come: 100%|██████████| 249/249 [00:18<00:00, 13.8it/s] \n",
      "gpt2 : lives: 100%|██████████| 249/249 [00:18<00:00, 13.8it/s] \n",
      "gpt2 : moved: 100%|██████████| 249/249 [00:18<00:00, 13.4it/s] \n",
      "roberta : come: 100%|██████████| 249/249 [00:17<00:00, 13.9it/s] \n",
      "roberta : lives: 100%|██████████| 249/249 [00:17<00:00, 14.1it/s] \n",
      "roberta : moved: 100%|██████████| 249/249 [00:17<00:00, 14.0it/s] \n",
      "mpnet : come: 100%|██████████| 249/249 [00:17<00:00, 14.4it/s] \n",
      "mpnet : lives: 100%|██████████| 249/249 [00:17<00:00, 14.1it/s] \n",
      "mpnet : moved: 100%|██████████| 249/249 [00:17<00:00, 14.2it/s] \n"
     ]
    }
   ],
   "source": [
    "# Countries\n",
    "series = countries.Name\n",
    "for model_name in models_list:\n",
    "    token = tokenizers[model_name]\n",
    "    model = models[model_name]\n",
    "    size = models_output_size[model_name]\n",
    "    for i, ctx in enumerate(contexts):\n",
    "        buffer_arr = np.empty((len(series),size))\n",
    "        for ind,entry in tqdm.tqdm(enumerate(series),desc=model_name + ' : ' + short_ctxts[i], unit_scale=True, total=len(series)):\n",
    "            inputs = token(ctx+\" \"+entry,return_tensors=\"pt\")\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            #If the entry is split in multiple tokens, we need to aggregate the tensors\n",
    "            expected_length = len(token([entry],is_split_into_words=True,add_special_tokens=False)['input_ids']) #number of tokens for the entry\n",
    "            last_ctx_token = token(ctx,add_special_tokens=False)['input_ids'][-1] #last token of the context string\n",
    "            start_index = inputs['input_ids'][0].tolist().index(last_ctx_token)+1 #first index of the entry's tensors\n",
    "\n",
    "            entry_embedding = outputs.last_hidden_state[0][start_index:start_index+expected_length].mean(axis=0)\n",
    "            buffer_arr[ind] = entry_embedding.detach().numpy()\n",
    "    \n",
    "        with open('embd_files/'+model_name+'_'+ short_ctxts[i] + '_countries.npy','wb') as f:\n",
    "            np.save(file=f,arr=buffer_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
